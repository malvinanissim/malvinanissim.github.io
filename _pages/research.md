---
layout: single
toc: true
toc_label: "Topic Overview"
author_profile: true
title: "Research"
permalink: /research/
header: 
       overlay_image: "assets/images/team-ngram.jpg"
       overlay_filter: 0.5
       cta_label: "celebrating with my students the first place at the PAN 2017 competition on author profiling"
       cta_url: "http://pan.webis.de/clef17/pan17-web/author-profiling.html"

sidebar:
  - title: "Computational Linguistics in Groningen"
    image: assets/images/CL.jpg
    image_alt: "CL"
    text: 'I am the coordinator of the Computational Linguistics group of <a href="https://www.rug.nl/research/clcg/research/">CLCG</a>'
  - title: "Social Media Sensing"
    text: "I am the scientific coordinator of the Social Media Sensing group at the RuG (SMS-RuG)."

---

My research interests are in the area of Computational Linguistics, Language Technology, and Digital Humanities. 
These are topics I work (or have worked) on. Currently more active ones are listed first.

## Style and Style Transfer


## Author Analysis
I am interested automatic analysis of authorship, both in terms of determining whether two texts are written 
by the same person or not (_authorship attribution_), as well as in terms of identifying some 
characteristics of the author, such as gender and age (_author profiling_). A few pointers:
- A [demo](https://aabeta.herokuapp.com/) of both profiling and attribution using our systems that participated to the [PAN](https://pan.webis.de/) competitions. At PAN 2016 and 2017 our systems won the competitions.
- A [short video](https://www.rug.nl/about-us/news-and-events/news/archief2017/nieuwsberichten/0301-unifocusnissim) where I explain how we do authorship attribution.
- I co-organise [the first truly cross-genre task on author profiling in Italian](https://sites.google.com/view/gxg2018/).

## Sentiment and Emotion Analysis

I use language processing tools to analyse and predict the way people express themselves on social media. I have pioneered this work on Italian, but I also work with other languages. I am also one of the initiators and scientific coordinators of the Social Media Sensing group at the University of Groningen.

- We have created [TWITA](http://www.let.rug.nl/basile/twita/about.php), a corpus of Italian tweets, tokenised, POS-tagged, and (automatically) sentiment annotated. 
- I am the co-organiser of the first and second campaigns for sentiment analysis in Italian: [SENTIPOLC 2014](http://www.di.unito.it/~tutreeb/sentipolc-evalita14/index.html) and [SENTIPOLC 2016](http://www.di.unito.it/~tutreeb/sentipolc-evalita16/), run within the framework of [EVALITA](http://www.evalita.it/). 
- I co-organise the [PEOPLES](https://peopleswksh.github.io) workshop, in 2018 at its second edition. PEOPLES is a forum for discussing the interplay of various aspects of profiling/sentiment/emotions in social media, and is co-located with major events (COLING 2016, NAACL 2018).
- I have also worked with emotion and controversy detection, exploiting Facebook reactions as distant silver labels for training.

## Modality
Investigation on _factuality_ and _speaker's attitude_
in a typologically sound, cross-linguistic perspective, including the promotion of a multilingual annotation scheme. 
Analysis and proposals for the crucial issue of annotation units. Related fields: opinion mining, sentiment analysis.

## Multiword units
Analysis of semantics of complex nominals of the type N+P+N in Italian. Development of models for the interpretation of P thanks to the lexical semantics of both nouns involved. Integration of hypernym information from MultiWordNet. Analysis of (atypical) compounds of the type N+N in Italian through corpus-based studies and a language typology perspective. Multiword expressions in Italian: corpus-based work towards characterisation, creation of lexical resources, and modelling of internal morphology. Automatic processing.

## Regular Polysemy
Extensive corpus-based studies with special attention to proper nouns. Creation of several annotated freely available datasets. Innovative view of metonymy resolution as a
classification task, partially akin to word sense disambiguation. Development of machine learning algorithms for the
automatic resolution of metonymy. Innovative integration of thesaurus to alleviate data sparseness exploiting regularity of phenomenon.
Organisation of shared task within the SemEval 2007 evaluation campaign.


## Discourse/Dialogue Structure
Development of specific annotation schemes and creation of annotated corpora for information status in dialogue. Innovative framework for information structure that comprises both spoken and written data. Coordination of annotation project. Analysis of paraphrases in annotated dialogues with specific attention to alternative constructions (e.g. pre- vs post-nominal genitive). Development of statistical model for automatic assignment of information status to discourse entities.

## Entity Recognition
Use of statistical models for the resolution of various entities in several kinds of text. 
Particular attention to geographical, astronomical, and biomedical text. Best system for gene/protein recognition in 2004 (Biocreative challenge). Investigated issues concerning the granularity of classification and relation extraction. Excellent experience in designing and supervising named entity annotation tasks.


<!--\textbf{Semantic Web and New Media} Use and exploitation of semantic wikis towards the generation of data for training statistical language models. 
Collaborative ways of building (lexical/linguistic) resources. 
(Co-)starter of \textit{Senso Comune}, a project for the creation of a resource encoding 
common-sense knowledge for Italian (reference resources for English: FrameNet, Open Mind). 
-->

## Anaphora Resolution
Theoretical and corpus-based description of bridging anaphors and non-anaphoric definite NPs. Theoretical and corpus-based comparison of definite NPs with genitive constructions.
Development of both symbolic and statistical methods for the resolution of different types of lexical anaphora. Innovative use of the Web as a source of knowledge for this task. Several annotation projects in Italian and English on written texts and dialogues.